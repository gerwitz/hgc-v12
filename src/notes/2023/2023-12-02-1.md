---
date: 2023-12-02T20:48:47.645+01:00
---
I am fascinated by prompt hacking that uses [emotional appeals to affect the behavior of LLMs](https://arxiv.org/abs/2307.11760). A long-lived LLM might be used to prototype manipulation techniques, perhaps by other models in an adversarial training arrangement.

In any event, many humans may learn social interactions by interacting with them as much as or instead of with peers. I'm not sure if that's troubling or promising!

