---
date: 2025-07-11
categories:
- work
content-tags:
- ai
---
As I enjoy watching models explain their reasoning through work I've given them, I keep thinking about the recent paper _[_Chain-of-Thought Is Not Explainability_](https://www.alphaxiv.org/abs/2025.02v3) and how much we should remind people that rationalization is not always insight:

 > verbalised chains are frequently unfaithful, diverging from the true hidden computations that drive a modelâ€™s predictions, and giving an incorrect picture of how models arrive at conclusions
